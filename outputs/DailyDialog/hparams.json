{
    "do_train": true,
    "do_test": false,
    "do_infer": false,
    "num_infer_batches": null,
    "hparams_file": null,
    "BPETextField": {
        "vocab_path": "model/Bert/vocab.txt",
        "filtered": false,
        "max_len": 256,
        "min_utt_len": 1,
        "max_utt_len": 50,
        "min_ctx_turn": 1,
        "max_ctx_turn": 16,
        "max_knowledge_num": 16,
        "max_knowledge_len": 16,
        "tokenizer_type": "Bert"
    },
    "Dataset": {
        "data_dir": "data/DailyDialog",
        "data_type": "multi"
    },
    "Trainer": {
        "use_data_distributed": false,
        "valid_metric_name": "-loss",
        "num_epochs": 20,
        "save_dir": "outputs/DailyDialog",
        "batch_size": 6,
        "log_steps": 100,
        "valid_steps": 2000,
        "save_checkpoint": false,
        "save_summary": false,
        "shuffle": true,
        "sort_pool_size": 0
    },
    "Model": {
        "init_checkpoint": "model/PLATO",
        "model": "UnifiedTransformer",
        "num_token_embeddings": -1,
        "num_pos_embeddings": 512,
        "num_type_embeddings": 2,
        "num_turn_embeddings": 16,
        "num_latent": 20,
        "tau": 0.67,
        "with_bow": true,
        "hidden_dim": 768,
        "num_heads": 12,
        "num_layers": 12,
        "padding_idx": 0,
        "dropout": 0.1,
        "embed_dropout": 0.0,
        "attn_dropout": 0.1,
        "ff_dropout": 0.1,
        "use_discriminator": true,
        "dis_ratio": 1.0,
        "weight_sharing": true,
        "pos_trainable": true,
        "two_layer_predictor": false,
        "bidirectional_context": true,
        "label_smooth": 0.0,
        "initializer_range": 0.02,
        "lr": 1e-05,
        "weight_decay": 0.0,
        "max_grad_norm": null
    },
    "Generator": {
        "generator": "BeamSearch",
        "min_gen_len": 1,
        "max_gen_len": 30,
        "beam_size": 5,
        "length_average": false,
        "length_penalty": -1.0,
        "ignore_unk": true
    }
}